{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 12:17:39.573061: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.initializers import RandomUniform\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = loadtxt('../../data/monks-1.train',\n",
    "                         delimiter=' ', usecols=range(1, 8))\n",
    "test1 = loadtxt('../../data/monks-1.test',\n",
    "                        delimiter=' ', usecols=range(1, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=train1[:, 1:7]\n",
    "y_train1=train1[:, 0]\n",
    "\n",
    "X_test1=test1[:, 1:7]\n",
    "y_test1=test1[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=enc.fit_transform(X_train1).toarray()\n",
    "X_test1=enc.fit_transform(X_test1).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modelCV(lr=0.1, mom=0.1, act='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=17, \n",
    "                    kernel_initializer=RandomUniform(minval=-0.1, maxval=0.1, seed=1), \n",
    "                    activation=act,\n",
    "                    kernel_regularizer=l2(0.0001)\n",
    "                   ))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=['accuracy'], optimizer= SGD(lr=lr, momentum=mom, nesterov=False))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 12:47:05.030010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-29 12:47:05.030010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-29 12:47:17.755434: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-29 12:47:17.755519: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "4/4 - 2s - loss: 0.2439 - accuracy: 0.5854 - 2s/epoch - 504ms/step\n",
      "4/4 - 2s - loss: 0.2520 - accuracy: 0.5060 - 2s/epoch - 499ms/step\n",
      "Epoch 2/10\n",
      "Epoch 2/10\n",
      "4/4 - 0s - loss: 0.2515 - accuracy: 0.5060 - 80ms/epoch - 20ms/step\n",
      "4/4 - 0s - loss: 0.2431 - accuracy: 0.5854 - 79ms/epoch - 20ms/step\n",
      "Epoch 3/10\n",
      "Epoch 3/10\n",
      "4/4 - 0s - loss: 0.2425 - accuracy: 0.5854 - 54ms/epoch - 14ms/step\n",
      "4/4 - 0s - loss: 0.2502 - accuracy: 0.5060 - 56ms/epoch - 14ms/step\n",
      "Epoch 4/10\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 0.2494 - accuracy: 0.5060 - 16ms/epoch - 4ms/step\n",
      "4/4 - 0s - loss: 0.2416 - accuracy: 0.5854 - 19ms/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "Epoch 5/10\n",
      "4/4 - 0s - loss: 0.2408 - accuracy: 0.5854 - 17ms/epoch - 4ms/step\n",
      "4/4 - 0s - loss: 0.2492 - accuracy: 0.5060 - 17ms/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "Epoch 6/10\n",
      "4/4 - 0s - loss: 0.2487 - accuracy: 0.5060 - 17ms/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2399 - accuracy: 0.5854 - 22ms/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2478 - accuracy: 0.5060 - 17ms/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 0.2400 - accuracy: 0.5854 - 22ms/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 0.2476 - accuracy: 0.5060 - 20ms/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2386 - accuracy: 0.5854 - 14ms/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2471 - accuracy: 0.5060 - 19ms/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2379 - accuracy: 0.5854 - 35ms/epoch - 9ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2466 - accuracy: 0.5060 - 25ms/epoch - 6ms/step\n",
      "4/4 - 0s - loss: 0.2370 - accuracy: 0.5854 - 16ms/epoch - 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "4/4 - 1s - loss: 0.3400 - accuracy: 0.4096 - 1s/epoch - 320ms/step\n",
      "Epoch 2/10\n",
      "4/4 - 0s - loss: 0.3244 - accuracy: 0.4096 - 21ms/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "4/4 - 0s - loss: 0.3103 - accuracy: 0.4096 - 47ms/epoch - 12ms/step\n",
      "4/4 - 1s - loss: 0.2406 - accuracy: 0.5854 - 1s/epoch - 337ms/step\n",
      "Epoch 2/10\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 0.2972 - accuracy: 0.4096 - 53ms/epoch - 13ms/step\n",
      "Epoch 5/10\n",
      "4/4 - 0s - loss: 0.2402 - accuracy: 0.5854 - 55ms/epoch - 14ms/step\n",
      "Epoch 3/10\n",
      "4/4 - 0s - loss: 0.2395 - accuracy: 0.5854 - 29ms/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 0.2877 - accuracy: 0.4096 - 41ms/epoch - 10ms/step\n",
      "Epoch 6/10\n",
      "4/4 - 0s - loss: 0.2384 - accuracy: 0.5854 - 20ms/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "4/4 - 0s - loss: 0.2798 - accuracy: 0.4096 - 28ms/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2373 - accuracy: 0.5854 - 18ms/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "4/4 - 0s - loss: 0.2718 - accuracy: 0.4096 - 25ms/epoch - 6ms/step\n",
      "4/4 - 0s - loss: 0.2369 - accuracy: 0.5854 - 22ms/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2657 - accuracy: 0.4096 - 25ms/epoch - 6ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2609 - accuracy: 0.4096 - 28ms/epoch - 7ms/step\n",
      "4/4 - 0s - loss: 0.2364 - accuracy: 0.5854 - 57ms/epoch - 14ms/step\n",
      "Epoch 10/10\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 0.2564 - accuracy: 0.4096 - 26ms/epoch - 7ms/step\n",
      "4/4 - 0s - loss: 0.2356 - accuracy: 0.5854 - 38ms/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2346 - accuracy: 0.5854 - 26ms/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2342 - accuracy: 0.5854 - 13ms/epoch - 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "4/4 - 2s - loss: 0.2536 - accuracy: 0.4940 - 2s/epoch - 401ms/step\n",
      "Epoch 2/10\n",
      "4/4 - 0s - loss: 0.2518 - accuracy: 0.4940 - 25ms/epoch - 6ms/step\n",
      "Epoch 3/10\n",
      "4/4 - 0s - loss: 0.2506 - accuracy: 0.4940 - 35ms/epoch - 9ms/step\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 0.2495 - accuracy: 0.4940 - 10ms/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "4/4 - 0s - loss: 0.2488 - accuracy: 0.4940 - 33ms/epoch - 8ms/step\n",
      "Epoch 6/10\n",
      "4/4 - 2s - loss: 0.2471 - accuracy: 0.5904 - 2s/epoch - 384ms/step\n",
      "Epoch 2/10\n",
      "4/4 - 0s - loss: 0.2476 - accuracy: 0.4940 - 37ms/epoch - 9ms/step\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2460 - accuracy: 0.5904 - 35ms/epoch - 9ms/step\n",
      "Epoch 3/10\n",
      "4/4 - 0s - loss: 0.2462 - accuracy: 0.4940 - 29ms/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 0.2452 - accuracy: 0.5904 - 39ms/epoch - 10ms/step\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 0.2456 - accuracy: 0.5060 - 37ms/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2451 - accuracy: 0.5181 - 54ms/epoch - 14ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2436 - accuracy: 0.5904 - 60ms/epoch - 15ms/step\n",
      "Epoch 5/10\n",
      "4/4 - 0s - loss: 0.2439 - accuracy: 0.6386 - 52ms/epoch - 13ms/step\n",
      "4/4 - 0s - loss: 0.2428 - accuracy: 0.5904 - 49ms/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "4/4 - 0s - loss: 0.2425 - accuracy: 0.5904 - 15ms/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2419 - accuracy: 0.5904 - 14ms/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 0.2418 - accuracy: 0.5904 - 32ms/epoch - 8ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2410 - accuracy: 0.5904 - 12ms/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2407 - accuracy: 0.5904 - 33ms/epoch - 8ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "4/4 - 2s - loss: 0.2948 - accuracy: 0.4146 - 2s/epoch - 393ms/step\n",
      "Epoch 2/10\n",
      "4/4 - 0s - loss: 0.2802 - accuracy: 0.4146 - 62ms/epoch - 15ms/step\n",
      "Epoch 3/10\n",
      "4/4 - 2s - loss: 0.2738 - accuracy: 0.5060 - 2s/epoch - 389ms/step\n",
      "Epoch 2/10\n",
      "4/4 - 0s - loss: 0.2665 - accuracy: 0.4146 - 26ms/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 0.2670 - accuracy: 0.5060 - 16ms/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "4/4 - 0s - loss: 0.2578 - accuracy: 0.4146 - 13ms/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "4/4 - 0s - loss: 0.2621 - accuracy: 0.5060 - 22ms/epoch - 5ms/step\n",
      "4/4 - 0s - loss: 0.2506 - accuracy: 0.4146 - 19ms/epoch - 5ms/step\n",
      "Epoch 4/10\n",
      "Epoch 6/10\n",
      "4/4 - 0s - loss: 0.2583 - accuracy: 0.5060 - 21ms/epoch - 5ms/step\n",
      "4/4 - 0s - loss: 0.2467 - accuracy: 0.4634 - 25ms/epoch - 6ms/step\n",
      "Epoch 5/10\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2436 - accuracy: 0.7805 - 19ms/epoch - 5ms/step\n",
      "4/4 - 0s - loss: 0.2557 - accuracy: 0.5060 - 21ms/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "Epoch 6/10\n",
      "4/4 - 0s - loss: 0.2405 - accuracy: 0.7439 - 17ms/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2535 - accuracy: 0.5060 - 19ms/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2392 - accuracy: 0.7439 - 30ms/epoch - 8ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2520 - accuracy: 0.5060 - 33ms/epoch - 8ms/step\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 0.2368 - accuracy: 0.5854 - 23ms/epoch - 6ms/step\n",
      "4/4 - 0s - loss: 0.2500 - accuracy: 0.5060 - 21ms/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2483 - accuracy: 0.5060 - 57ms/epoch - 14ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2475 - accuracy: 0.5060 - 22ms/epoch - 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "4/4 - 3s - loss: 0.2511 - accuracy: 0.5904 - 3s/epoch - 630ms/step\n",
      "Epoch 2/10\n",
      "4/4 - 3s - loss: 0.2738 - accuracy: 0.4146 - 3s/epoch - 645ms/step\n",
      "4/4 - 0s - loss: 0.2495 - accuracy: 0.5904 - 65ms/epoch - 16ms/step\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "4/4 - 0s - loss: 0.2479 - accuracy: 0.5904 - 17ms/epoch - 4ms/step\n",
      "4/4 - 0s - loss: 0.2636 - accuracy: 0.4146 - 18ms/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 0.2561 - accuracy: 0.4146 - 18ms/epoch - 5ms/step\n",
      "4/4 - 0s - loss: 0.2465 - accuracy: 0.5904 - 23ms/epoch - 6ms/step\n",
      "Epoch 5/10\n",
      "Epoch 4/10\n",
      "4/4 - 0s - loss: 0.2457 - accuracy: 0.5904 - 20ms/epoch - 5ms/step\n",
      "4/4 - 0s - loss: 0.2504 - accuracy: 0.5366 - 23ms/epoch - 6ms/step\n",
      "Epoch 6/10\n",
      "Epoch 5/10\n",
      "4/4 - 0s - loss: 0.2437 - accuracy: 0.5904 - 14ms/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "4/4 - 0s - loss: 0.2468 - accuracy: 0.5854 - 18ms/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "4/4 - 0s - loss: 0.2452 - accuracy: 0.5854 - 18ms/epoch - 5ms/step\n",
      "4/4 - 0s - loss: 0.2432 - accuracy: 0.5904 - 29ms/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 0.2436 - accuracy: 0.5854 - 14ms/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "4/4 - 0s - loss: 0.2430 - accuracy: 0.5904 - 26ms/epoch - 6ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2424 - accuracy: 0.5854 - 18ms/epoch - 5ms/step\n",
      "Epoch 9/10\n",
      "4/4 - 0s - loss: 0.2427 - accuracy: 0.5904 - 18ms/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2412 - accuracy: 0.5854 - 19ms/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "4/4 - 0s - loss: 0.2422 - accuracy: 0.5904 - 15ms/epoch - 4ms/step\n",
      "4/4 - 0s - loss: 0.2407 - accuracy: 0.5854 - 17ms/epoch - 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc4475d1160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6bbdd11f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/piyush/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cr/cspt5tz93w7cqfslq2qjbg_c0000gn/T/ipykernel_15684/1652180295.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m mlpr = GridSearchCV( model\n\u001b[1;32m     13\u001b[0m                     , hyper_params_space, scoring=['accuracy'], refit='accuracy', cv=3, n_jobs=2)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmlpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mresultGSCV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyper_params_space = {\n",
    "        'lr': [0.1, 0.2, 0.25, 0.3, 0.4, 0.5],\n",
    "        'mom': [0.1, 0.2, 0.3, 0.5, 0.7, 0.85, 0.9],\n",
    "        'act': ['sigmoid', 'relu']\n",
    "    },\n",
    "\n",
    "\n",
    "\n",
    "print('===================================')\n",
    "# verbose is set to 0, no output will be printed to the console during training\n",
    "model = KerasClassifier(build_fn=create_modelCV, batch_size=25, epochs=150, verbose=0)\n",
    "mlpr = GridSearchCV( model\n",
    "                    , hyper_params_space, scoring=['accuracy'], refit='accuracy', cv=3, n_jobs=2)\n",
    "mlpr.fit(X_train1, y_train1)\n",
    "print(\"DONE\")\n",
    "resultGSCV=pd.DataFrame(mlpr.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'act': 'relu', 'lr': 0.1, 'mom': 0.9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modelOP():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=17, activation=mlpr.best_params_['act'], kernel_initializer=RandomUniform(minval=-0.1, maxval=0.1, seed=1)\n",
    "                    , kernel_regularizer=l2(0.0001)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', metrics=['accuracy'], \n",
    "                  optimizer= SGD(lr=mlpr.best_params_['lr'], momentum=mlpr.best_params_['mom']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 3s 385ms/step - loss: 0.2531 - accuracy: 0.4113 - val_loss: 0.2472 - val_accuracy: 0.5255\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 0.2462 - accuracy: 0.5645 - val_loss: 0.2440 - val_accuracy: 0.6296\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2398 - accuracy: 0.6613 - val_loss: 0.2396 - val_accuracy: 0.5926\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2295 - accuracy: 0.6613 - val_loss: 0.2318 - val_accuracy: 0.6597\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.2168 - accuracy: 0.7016 - val_loss: 0.2226 - val_accuracy: 0.6968\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.2016 - accuracy: 0.7419 - val_loss: 0.2126 - val_accuracy: 0.7106\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.1834 - accuracy: 0.7581 - val_loss: 0.2042 - val_accuracy: 0.7083\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.1674 - accuracy: 0.7984 - val_loss: 0.1975 - val_accuracy: 0.7106\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 101ms/step - loss: 0.1565 - accuracy: 0.8145 - val_loss: 0.1922 - val_accuracy: 0.7176\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.1487 - accuracy: 0.8226 - val_loss: 0.1876 - val_accuracy: 0.7199\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1421 - accuracy: 0.8387 - val_loss: 0.1836 - val_accuracy: 0.7338\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.1359 - accuracy: 0.8468 - val_loss: 0.1810 - val_accuracy: 0.7407\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.1323 - accuracy: 0.8468 - val_loss: 0.1786 - val_accuracy: 0.7477\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1290 - accuracy: 0.8548 - val_loss: 0.1754 - val_accuracy: 0.7546\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1295 - accuracy: 0.8468 - val_loss: 0.1729 - val_accuracy: 0.7593\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.1223 - accuracy: 0.8548 - val_loss: 0.1781 - val_accuracy: 0.7546\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1228 - accuracy: 0.8548 - val_loss: 0.1760 - val_accuracy: 0.7569\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1220 - accuracy: 0.8548 - val_loss: 0.1744 - val_accuracy: 0.7639\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1197 - accuracy: 0.8548 - val_loss: 0.1697 - val_accuracy: 0.7593\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.1183 - accuracy: 0.8548 - val_loss: 0.1702 - val_accuracy: 0.7662\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1179 - accuracy: 0.8629 - val_loss: 0.1668 - val_accuracy: 0.7662\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1145 - accuracy: 0.8710 - val_loss: 0.1676 - val_accuracy: 0.7639\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1130 - accuracy: 0.8629 - val_loss: 0.1649 - val_accuracy: 0.7639\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.1104 - accuracy: 0.8629 - val_loss: 0.1589 - val_accuracy: 0.7685\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1081 - accuracy: 0.8629 - val_loss: 0.1539 - val_accuracy: 0.7708\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1059 - accuracy: 0.8548 - val_loss: 0.1577 - val_accuracy: 0.7616\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1022 - accuracy: 0.8629 - val_loss: 0.1482 - val_accuracy: 0.7755\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0968 - accuracy: 0.8710 - val_loss: 0.1426 - val_accuracy: 0.7731\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0943 - accuracy: 0.8790 - val_loss: 0.1378 - val_accuracy: 0.7824\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0916 - accuracy: 0.8952 - val_loss: 0.1343 - val_accuracy: 0.7894\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0863 - accuracy: 0.8871 - val_loss: 0.1247 - val_accuracy: 0.8102\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0836 - accuracy: 0.9113 - val_loss: 0.1240 - val_accuracy: 0.8102\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0806 - accuracy: 0.9274 - val_loss: 0.1207 - val_accuracy: 0.8218\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0765 - accuracy: 0.9274 - val_loss: 0.1090 - val_accuracy: 0.8449\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0713 - accuracy: 0.9274 - val_loss: 0.1128 - val_accuracy: 0.8380\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0687 - accuracy: 0.9355 - val_loss: 0.0996 - val_accuracy: 0.8866\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0634 - accuracy: 0.9758 - val_loss: 0.0974 - val_accuracy: 0.8889\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0595 - accuracy: 0.9677 - val_loss: 0.0967 - val_accuracy: 0.8866\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0572 - accuracy: 0.9516 - val_loss: 0.0903 - val_accuracy: 0.9074\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0554 - accuracy: 0.9919 - val_loss: 0.0825 - val_accuracy: 0.9282\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0499 - accuracy: 0.9919 - val_loss: 0.0811 - val_accuracy: 0.9236\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.0484 - accuracy: 0.9758 - val_loss: 0.0793 - val_accuracy: 0.9167\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.0465 - accuracy: 0.9839 - val_loss: 0.0703 - val_accuracy: 0.9583\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0426 - accuracy: 0.9919 - val_loss: 0.0738 - val_accuracy: 0.9306\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0403 - accuracy: 0.9919 - val_loss: 0.0649 - val_accuracy: 0.9676\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0383 - accuracy: 0.9919 - val_loss: 0.0623 - val_accuracy: 0.9722\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.0361 - accuracy: 0.9919 - val_loss: 0.0638 - val_accuracy: 0.9468\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9838\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0322 - accuracy: 0.9919 - val_loss: 0.0586 - val_accuracy: 0.9630\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0318 - accuracy: 0.9919 - val_loss: 0.0511 - val_accuracy: 0.9861\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9838\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0283 - accuracy: 0.9919 - val_loss: 0.0495 - val_accuracy: 0.9769\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9931\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9884\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9954\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9931\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9954\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9954\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9861\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9954\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9954\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9907\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9954\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 87ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9884\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9954\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9954\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9954\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 0.9907\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9954\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9954\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9954\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9954\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9954\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9954\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9954\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9954\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9954\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9954\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9954\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 0.9954\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9954\n",
      "Epoch 83/150\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 0.9954\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9954\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 0.9954\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0184 - val_accuracy: 0.9954\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 76ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0160 - val_accuracy: 0.9954\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9954\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9954\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9954\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9954\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9954\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9954\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9954\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9954\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9954\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9954\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9977\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 0.9954\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 0.9954\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9977\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 74ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 106ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#instantiate the model and run it\n",
    "#es = EarlyStopping(monitor='val_loss', patience=30)\n",
    "#mc = ModelCheckpoint('best_model_NOREG.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model1 = create_modelOP()\n",
    "\n",
    "history1 = model1.fit(X_train1, y_train1, \n",
    "                      validation_data=(X_test1, y_test1), \n",
    "                      epochs=150, \n",
    "                      batch_size=25, \n",
    "                      #callbacks=[es,mc]\n",
    "                     ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See if we have overfitting\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(history1['loss'], label='MSE')\n",
    "plt.plot(history1['accuracy'], label='Accuracy', linestyle='dashed')\n",
    "#plt.plot(history1['val_loss'], label='Test')\n",
    "#plt.title('Learning curves for training', fontsize = 18)\n",
    "plt.xlabel('Epochs')\n",
    "#plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See if we have overfitting\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(history1['val_loss'], label='MSE')\n",
    "plt.plot(history1['val_accuracy'], label='Accuracy', linestyle='dashed')\n",
    "#plt.plot(history1['val_loss'], label='Test')\n",
    "#plt.title('Learning curves for test', fontsize = 18)\n",
    "plt.xlabel('Epochs')\n",
    "#plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "mse, accuracy = model1.evaluate(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test 1.0\n",
      "MSE on Test 0.008655073121190071\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Test\", accuracy)\n",
    "print(\"MSE on Test\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "mse_tr, accuracy_tr = model1.evaluate(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training 1.0\n",
      "MSE on Training 0.0051472666673362255\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on Training\", accuracy_tr)\n",
    "print(\"MSE on Training\", mse_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "43b5c63db261ca5051cb55de1c6286202162451824cb753635f4f1f1c93d73cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
